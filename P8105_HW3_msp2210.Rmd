---
title: "Homework 3"
author: "Mukta Patwari"
date: "2025-10-09"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Loading and inspecting data
```{r}
data("instacart")
```

There are `r nrow(instacart)` observations in this dataset, with the following `r ncol(instacart)` variables: `r colnames(instacart)`. Some of the key variables are `order_id` and `user_id` which give information on the individual ordering these items on Instacart. Other key variables are `product_name`, which refers to what product(s) the individual ordered, and `aisle` and `department` which give location data within the grocery store.

**How many aisles are there, and which aisles are the most items ordered from?**

```{r}
instacart %>% 
  distinct(aisle) %>% 
  nrow()

instacart %>% 
  group_by(aisle) %>% 
  summarize(
    n = n()
  ) %>% 
  arrange(desc(n))
```

There are 134 different aisles in this dataset. The top 10 most frequented aisles were: fresh vegetables, fresh fruits, packaged vegetables/fruits, yogurt, packaged cheese, water/seltzer/sparkling water, milk, chips/pretzels, soy/lactose free, and bread.

**Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.**

```{r aisle-plot}
instacart %>% 
  group_by(aisle) %>% 
  summarize(
    n = n()
  ) %>%
  filter(n > 10000) %>%
  ggplot(aes(x = reorder(aisle, n), y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(
    title = "Items Ordered by Aisle (>10,000 Orders)",
    x = "Aisle Name",
    y = "Number of Items Ordered"
  )
```

This plot corroborates the results that were seen in the earlier question, about how many items were ordered from each aisle which aisles had the most items ordered - fresh vegetables has a high item count at greater >120000 orders, as does the fresh fruits category.

**Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.**

```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  count(aisle, product_name) %>%
  group_by(aisle) %>% 
  mutate(product_rank = min_rank(desc(n))) %>% 
  filter(product_rank <= 3) %>%
  arrange(aisle, product_rank) %>%
  select(-product_rank) %>% 
  knitr::kable(digits = 2)
```

The table shows that in the baking ingredidents aisle, the products light brown sugar, pure baking soda, and cane sugar were most ordered; in the dog food care aisle, the most ordered products were "Snack Sticks Chicken & Rice Recipe Dog Treats", "Organix Chicken & Brown Rice Recipe" and small dog biscuits; in the packaged vegetables fruits aisle, the most ordered items were organic baby spinach, organic raspberries, and organic blueberries.

**Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).**

```{r}
instacart %>%
  mutate(order_dow = factor(order_dow, 
    levels = 0:6,
    labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day, na.rm = TRUE)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable(digits = 1)
```

This table shows the mean order hour of day for each day of the week that the coffee ice cream and pink lady apples were ordered. On Sunday, coffee ice cream was ordered at hour 13.8, which when converted to an hour-time format, would probably be around 1:40. Similarly, the mean hour that pink lady apples were ordered was 13.4, which would be around 1:20. The remaining columns are the days of the week Monday-Saturday, with the corresponding mean hours for the same products ordered.

## Problem 2

Loading, importing, tidying zipcodes
```{r}
zipcodes_df =
  read_csv(
    "zillow_data/Zip Codes.csv", 
    na = c("NA", ".", "")
    ) %>%
  janitor::clean_names() %>%
  filter(!(zip_code %in% c(10463, 11201) & county == "New York")) %>% 
  select(-state_fips, -county_code, -county_fips, -file_date)


# Duplicated zip-codes:
zipcodes_df[duplicated(zipcodes_df$zip_code),]
```

Loading, importing, tidying rental price
```{r}
rentalprice_df =
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) %>% 
  rename_with(janitor::make_clean_names, .cols = 1:9) %>% 
  pivot_longer(
    cols = "2015-01-31":"2024-08-31",
    names_to = "date",
    values_to = "rent",
  ) %>%
  mutate(
    date = as.Date(date)
  ) %>%
  separate(
    date, into = c("year", "month", "day"),
    convert = TRUE,
  ) %>% 
  rename(zip_code = region_name, county = county_name) %>%
  mutate(
    county = (str_remove(county, "County"))
  ) %>% 
  select(-region_id, -size_rank, -region_type, -state_name, -metro, -county)
```

Merging datasets into zillow dataframe
```{r}
zillow_df =
  left_join(
    rentalprice_df, zipcodes_df, by = "zip_code"
    ) %>% 
  relocate(year, month, day, state, city, county, zip_code, neighborhood, rent)
```